#!/bin/bash
# Orchestrateur principal du pipeline de donn√©es e-commerce
# Ce script pilote l'ex√©cution des diff√©rentes √©tapes du traitement des donn√©es
# D√©finition des chemins
PIPELINE_ROOT="$(dirname "$0")/.."   # R√©pertoire racine du pipeline
LOG_DIR="$PIPELINE_ROOT/logs"        # R√©pertoire pour stocker les fichiers de log
mkdir -p "$LOG_DIR"                  # Cr√©ation du dossier logs si n√©cessaire
LOG_FILE="$LOG_DIR/pipeline_$(date '+%Y%m%d_%H%M%S').log"  # Fichier de log horodat√©






# ====================================
# ‚úÖ Verrouillage pour √©viter les doublons
# ====================================

LOCK_FILE="/tmp/data_pipeline.lock"  # Fichier de verrouillage pour √©viter les ex√©cutions multiples

if [ -f "$LOCK_FILE" ]; then
    echo "‚ùå Pipeline d√©j√† en cours. Fichier lock d√©tect√©." | tee -a "$LOG_FILE"
    exit 1  # Si le fichier lock existe, on quitte
fi

touch "$LOCK_FILE"  # Cr√©ation du fichier lock

# Suppression automatique du lock √† la fin ou en cas de crash
trap "rm -f $LOCK_FILE" EXIT

# ====================================
# üß© Fonctions principales du pipeline
# ====================================

initialize_data_pipeline() {
    echo "üîß Initialisation de l'environnement..." | tee -a "$LOG_FILE"

    # V√©rifie que tous les r√©pertoires de donn√©es existent (cr√©ation si n√©cessaire)
    for dir in raw staging processed quality archive; do
        mkdir -p "$PIPELINE_ROOT/data/$dir"
    done

    # Cr√©ation du dossier de configuration s‚Äôil est manquant (utile en cas de d√©ploiement initial)
    mkdir -p "$PIPELINE_ROOT/config"

    # V√©rifie que les fichiers de configuration critiques existent, sinon avertit
    for config_file in data_schemas.json business_rules.yaml quality_thresholds.yaml pipeline_config.yaml; do
        if [ ! -f "$PIPELINE_ROOT/config/$config_file" ]; then
            echo "‚ö†Ô∏è  Fichier de configuration manquant : $config_file" | tee -a "$LOG_FILE"
        fi
    done

    # Nettoyage optionnel du dossier staging pour √©viter les conflits avec d'anciens fichiers
    if [ -n "$(ls -A "$PIPELINE_ROOT/data/staging/" 2>/dev/null)" ]; then
        echo "üßπ Nettoyage du dossier staging..." | tee -a "$LOG_FILE"
        rm -r "$PIPELINE_ROOT/data/staging/"*
    fi

    # Chargement des variables d'environnement depuis un fichier pipeline_config.yaml (facultatif ici)
    if [ -f "$PIPELINE_ROOT/config/pipeline_config.yaml" ]; then
    
        CONFIG_PATH="$PIPELINE_ROOT/config/pipeline_config.yaml"
        DATA_WORKERS=$(yq eval '.data_workers' "$CONFIG_PATH")
        CHUNK_SIZE_MB=$(yq eval '.chunk_size_mb' "$CONFIG_PATH")
        QUALITY_THRESHOLD=$(yq eval '.quality_threshold' "$CONFIG_PATH")
        PROCESSING_TIMEOUT=$(yq eval '.processing_timeout' "$CONFIG_PATH")
        echo "‚öôÔ∏è  Configuration charg√©e : Workers=$DATA_WORKERS, Chunk=$CHUNK_SIZE_MB MB, Seuil=$QUALITY_THRESHOLD%, Timeout=$PROCESSING_TIMEOUT sec" | tee -a "$LOG_FILE"
    fi

    # Affichage d‚Äôun r√©sum√©
    echo "‚úÖ Initialisation termin√©e." | tee -a "$LOG_FILE"
}


scan_data_sources() {
    echo "üîé Scan des nouvelles sources de donn√©es..." | tee -a "$LOG_FILE"
    # Appel du script d√©di√© √† la d√©couverte des fichiers √† traiter
    "$PIPELINE_ROOT/orchestration/data_discovery.sh" >> "$LOG_FILE" 2>&1
}

distribute_processing() {
    echo "‚öôÔ∏è Lancement du traitement avec $DATA_WORKERS workers..." | tee -a "$LOG_FILE"
    # Appel du gestionnaire de traitement parall√®le avec passage du nombre de workers
    "$PIPELINE_ROOT/orchestration/worker_manager.sh" "$DATA_WORKERS" "$CHUNK_SIZE_MB" >> "$LOG_FILE" 2>&1
}

monitor_data_quality() {
    echo "üß™ V√©rification qualit√©..." | tee -a "$LOG_FILE"
    bash "$PIPELINE_ROOT/orchestration/quality_monitor.sh" "$QUALITY_THRESHOLD" >> "$LOG_FILE" 2>&1
}
run_alert_manager() {
    echo "üì£ Analyse des alertes qualit√©..." | tee -a "$LOG_FILE"
    "$PIPELINE_ROOT/monitoring/alert_manager.py" >> "$LOG_FILE" 2>&1

    if [ $? -eq 0 ]; then
        echo -e "\\033[32m‚úÖ Alerte qualit√© : aucun √©chec d√©tect√©.\\033[0m" | tee -a "$LOG_FILE"
    else
        echo -e "\\033[31müö® Alerte qualit√© : des √©checs ont √©t√© d√©tect√©s !\\033[0m" | tee -a "$LOG_FILE"
        echo -e "\\033[31mConsulte le fichier : data/quality/quality_alert.txt\\033[0m" | tee -a "$LOG_FILE"
    fi
}

consolidate_data_results() {
    echo "üì¶ consolidation des r√©sultats multi-sources..." | tee -a "$LOG_FILE"

    # Appel du script de jointure Python
    python3  "$PIPELINE_ROOT/transformations/data_joiner.py" >> "$LOG_FILE" 2>&1

    # V√©rification du r√©sultat
    if [ $? -eq 0 ]; then
        echo "‚úÖ consolidation termin√©e avec succ√®s." | tee -a "$LOG_FILE"
    else
        echo "‚ùå √âchec de l‚Äôagr√©gation des r√©sultats." | tee -a "$LOG_FILE"
    fi
}


archive_processed_data() {
    echo "üìÅ Archivage complet des donn√©es..." | tee -a "$LOG_FILE"

    ARCHIVE_ROOT="$PIPELINE_ROOT/data/archive"
    TIMESTAMP=$(date +"%Y%m%d_%H%M")
    ARCHIVE_DIR="$ARCHIVE_ROOT/archive_$TIMESTAMP"
    mkdir -p "$ARCHIVE_DIR"

    # 1. Archiver les donn√©es trait√©es
    echo "üì¶ Archivage de data/processed" | tee -a "$LOG_FILE"
    cp -r "$PIPELINE_ROOT/data/processed" "$ARCHIVE_DIR/processed"

    # 2. Archiver les rapports qualit√©
    echo "üì¶ Archivage de data/quality" | tee -a "$LOG_FILE"
    cp -r "$PIPELINE_ROOT/data/quality" "$ARCHIVE_DIR/quality"

    # 3. Compression unique
    TAR_PATH="$ARCHIVE_ROOT/archive_$TIMESTAMP.tar.gz"
    tar -czf "$TAR_PATH" -C "$ARCHIVE_ROOT" "archive_$TIMESTAMP"
    echo "üóúÔ∏è Archive compress√©e : $TAR_PATH" | tee -a "$LOG_FILE"

    # 4. Nettoyage du dossier temporaire d'archive
    rm -rf "$ARCHIVE_DIR"
    echo "üßπ Dossier interm√©diaire supprim√©." | tee -a "$LOG_FILE"

    # 5. Suppression des fichiers raw et staging (sans supprimer les dossiers)
    echo "üßº Nettoyage de data/raw et data/staging" | tee -a "$LOG_FILE"
    # find "$PIPELINE_ROOT/data/raw" -type f ! -name "*.zip" -exec rm -f {} \;
    find "$PIPELINE_ROOT/data/staging" -type f -exec rm -f {} \;
    find "$PIPELINE_ROOT/data/raw" -type f -name "*.done" -exec rm -f {} \;

    echo "‚úÖ Archivage complet termin√©." | tee -a "$LOG_FILE"
}

generate_dashboard() {
    echo "üìä G√©n√©ration du dashboard HTML..." | tee -a "$LOG_FILE"
    "$PIPELINE_ROOT/monitoring/dashboard_gen.py" >> "$LOG_FILE" 2>&1

    if [ $? -eq 0 ]; then
        echo "‚úÖ Dashboard g√©n√©r√© avec succ√®s." | tee -a "$LOG_FILE"
    else
        echo "‚ùå Erreur lors de la g√©n√©ration du dashboard." | tee -a "$LOG_FILE"
    fi
}


# ====================================
# üöÄ Lancement du pipeline
# ====================================

echo "üöÄ D√âMARRAGE DU PIPELINE √Ä $(date)" | tee -a "$LOG_FILE"

initialize_data_pipeline        # √âtape d'initialisation => dev ok
scan_data_sources               # D√©tection des fichiers nouveaux => dev ok
distribute_processing           # Lancement du traitement des donn√©es => dev ok
consolidate_data_results          # (optionnel) Fusion des r√©sultats => dev ok
monitor_data_quality            # Contr√¥le qualit√© avant-traitement => dev ok
run_alert_manager
generate_dashboard              # G√©n√©re le tableau de bord html de la qualit√© de donn√©e
archive_processed_data          # Archivage des fichiers trait√©s
echo "‚úÖ PIPELINE TERMIN√â √Ä $(date)" | tee -a "$LOG_FILE"
# üßπ Correction des permissions pour le runner GitHub
chown -R $(id -u):$(id -g) "$PIPELINE_ROOT/data" "$PIPELINE_ROOT/logs" 2>/dev/null || true
exit 0  # Fin du script avec succ√®s
